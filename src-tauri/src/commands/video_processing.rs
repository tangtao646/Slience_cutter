// src-tauri/src/commands/video_processing.rs
// è§†é¢‘å¤„ç†å‘½ä»¤

use crate::audio;
use crate::video;
use crate::app::ExportState;
use serde::{Deserialize, Serialize};
use std::path::Path;
use std::sync::atomic::Ordering;

// è§†é¢‘å¤„ç†è¯·æ±‚
#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct VideoProcessRequest {
    pub input_path: String,
    pub output_path: Option<String>,
    pub threshold_db: f64,
    pub min_silence_duration: f64,
    pub sample_rate: Option<u32>,
    pub segments: Option<Vec<crate::audio::SilenceSegment>>,
}

// è§†é¢‘å¤„ç†å“åº”
#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct VideoProcessResponse {
    pub success: bool,
    pub message: String,
    pub original_duration: f64,
    pub processed_duration: f64,
    pub silence_segments: usize,
    pub total_silence_removed: f64,
    pub compression_ratio: f64,
    pub output_path: String,
    pub processing_time: f64,
}

// å–æ¶ˆå¯¼å‡ºå‘½ä»¤
#[tauri::command]
pub async fn cancel_export(state: tauri::State<'_, ExportState>) -> Result<(), String> {
    state.is_cancelled.store(true, Ordering::SeqCst);
    println!("ğŸ›‘ æ”¶åˆ°å–æ¶ˆä¿¡å·ï¼Œå°†å°è¯•åœæ­¢å½“å‰å¤„ç†...");
    Ok(())
}

// è·å–è§†é¢‘ä¿¡æ¯
#[tauri::command]
pub async fn get_video_info(
    state: tauri::State<'_, crate::app::AppState>,
    path: String
) -> Result<video::VideoInfo, String> {
    let ffprobe_path = state.ffprobe_path.as_ref()
        .map(|p| p.to_string_lossy().to_string())
        .ok_or_else(|| "FFprobe not found".to_string())?;

    let result: Result<video::VideoInfo, Box<dyn std::error::Error>> = video::get_video_info(&ffprobe_path, &path).await;
    result.map_err(|e| format!("è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {}", e))
}

// æå–éŸ³é¢‘ (æµå¼åˆ†æç‰ˆ)
#[tauri::command]
pub async fn extract_audio(
    state: tauri::State<'_, crate::app::AppState>,
    path: String,
    sample_rate: Option<u32>,
    window: tauri::Window,
) -> Result<audio::AudioData, String> {
    let ffmpeg_path = state.ffmpeg_path.as_ref()
        .map(|p| p.to_string_lossy().to_string())
        .ok_or_else(|| "FFmpeg not found".to_string())?;
    
    let ffprobe_path = state.ffprobe_path.as_ref()
        .map(|p| p.to_string_lossy().to_string())
        .ok_or_else(|| "FFprobe not found".to_string())?;

    let sample_rate = sample_rate.unwrap_or(16000);
    println!("å¼€å§‹æµå¼æå–éŸ³é¢‘: {}, é‡‡æ ·ç‡: {}", path, sample_rate);
    
    // å‘é€åˆå§‹è¿›åº¦äº‹ä»¶
    use tauri::Emitter;
    let _ = window.emit("analysis-progress", serde_json::json!({
        "stage": "extracting",
        "message": "æ­£åœ¨æµå¼æå–éŸ³é¢‘...",
        "percent": 5
    }));
    
    // è°ƒç”¨æˆ‘ä»¬åœ¨ audio/mod.rs ä¸­å®šä¹‰çš„æµå¼å¤„ç†å‡½æ•°
    let result = audio::extract_audio_streaming(&ffmpeg_path, &ffprobe_path, &path, sample_rate, &window, -40.0).await;
    
    result.map_err(|e| {
        println!("æå–éŸ³é¢‘å¤±è´¥: {}", e);
        format!("æå–éŸ³é¢‘å¤±è´¥: {}", e)
    })
}

// æ£€æµ‹é™éŸ³
#[tauri::command]
pub async fn detect_silences(
    cache_id: String,
    audio_data: Option<Vec<f32>>,
    sample_rate: u32,
    threshold_db: f64,
    min_silence_duration: f64,
    window: tauri::Window,
) -> Result<Vec<audio::SilenceSegment>, String> {
    use tauri::Emitter;
    // å‘é€è¿›åº¦äº‹ä»¶
    let _ = window.emit("analysis-progress", serde_json::json!({
        "stage": "detecting",
        "message": "æ­£åœ¨åˆ†æéŸ³é¢‘é™éŸ³ç‰‡æ®µ...",
        "percent": 60
    }));
    
    audio::detect_silences(
        &cache_id,
        audio_data.as_deref(),
        sample_rate,
        threshold_db,
        min_silence_duration,
    )
    .map_err(|e| format!("é™éŸ³æ£€æµ‹å¤±è´¥: {}", e))
}

// å¤„ç†è§†é¢‘
#[tauri::command]
pub async fn process_video(
    app_state: tauri::State<'_, crate::app::AppState>,
    request: VideoProcessRequest,
    window: tauri::Window,
    state: tauri::State<'_, ExportState>,
) -> Result<VideoProcessResponse, String> {
    let ffmpeg_path = app_state.ffmpeg_path.as_ref()
        .map(|p| p.to_string_lossy().to_string())
        .ok_or_else(|| "FFmpeg not found".to_string())?;
    
    let ffprobe_path = app_state.ffprobe_path.as_ref()
        .map(|p| p.to_string_lossy().to_string())
        .ok_or_else(|| "FFprobe not found".to_string())?;

    // é‡ç½®å–æ¶ˆæ ‡è®°
    state.is_cancelled.store(false, Ordering::SeqCst);
    
    let start_time = std::time::Instant::now();

    // ç”Ÿæˆè¾“å‡ºè·¯å¾„
    let output_path = match request.output_path {
        Some(path) => path,
        None => generate_output_path(&request.input_path),
    };
    
    // æå–éŸ³é¢‘
    let sample_rate = request.sample_rate.unwrap_or(16000);
    println!("========== å¼€å§‹è§†é¢‘å¤„ç† ==========");
    println!("è¾“å…¥æ–‡ä»¶: {}", request.input_path);
    println!("è¾“å‡ºæ–‡ä»¶: {}", output_path);
    println!("é‡‡æ ·ç‡: {} Hz", sample_rate);
    println!("é˜ˆå€¼: {} dB", request.threshold_db);
    println!("æœ€å°é™éŸ³æ—¶é•¿: {} ç§’", request.min_silence_duration);
    
    // å¦‚æœå‰ç«¯å·²ç»æä¾›äº†é™éŸ³ç‰‡æ®µï¼ˆå¸¸è§æƒ…å†µï¼‰ï¼Œç›´æ¥è¿›å…¥å¤„ç†ï¼Œè·³è¿‡éŸ³é¢‘æå–å’Œé‡å¤æ£€æµ‹
    let silences = if let Some(segs) = request.segments {
        println!("âœ… ä½¿ç”¨å‰ç«¯æä¾›çš„é™éŸ³ç‰‡æ®µï¼Œæ•°é‡: {}", segs.len());
        segs
    } else {
        println!("æœªæä¾›ç‰‡æ®µï¼Œå¼€å§‹ä»è§†é¢‘æå–éŸ³é¢‘å¹¶æ£€æµ‹...");
        let result: Result<audio::AudioData, Box<dyn std::error::Error>> = audio::extract_audio_from_video(&ffmpeg_path, &ffprobe_path, &request.input_path, sample_rate, Some(&window)).await;
        let audio_data = result.map_err(|e| {
            eprintln!("âŒ éŸ³é¢‘æå–å¤±è´¥: {}", e);
            format!("éŸ³é¢‘æå–å¤±è´¥: {}", e)
        })?;
        
        println!("âœ… éŸ³é¢‘æå–æˆåŠŸ, ç¼“å­˜ID: {}", audio_data.cache_id);
        
        audio::detect_silences(
            &audio_data.cache_id,
            audio_data.samples.as_deref(),
            audio_data.sample_rate,
            request.threshold_db,
            request.min_silence_duration,
        )
        .map_err(|e| {
            eprintln!("âŒ é™éŸ³æ£€æµ‹å¤±è´¥: {}", e);
            format!("é™éŸ³æ£€æµ‹å¤±è´¥: {}", e)
        })?
    };
    
    println!("âœ… é™éŸ³æ£€æµ‹/è·å–å®Œæˆ: {} ä¸ªç‰‡æ®µ", silences.len());
    
    // å¤„ç†è§†é¢‘
    let cancel_signal = state.is_cancelled.clone();
    
    let video_result: Result<video::ProcessResult, Box<dyn std::error::Error>> = video::remove_silence_from_video(
        &ffmpeg_path,
        &ffprobe_path,
        &request.input_path,
        &output_path,
        &silences,
        Some(window),
        cancel_signal,
    ).await;
    let result = video_result.map_err(|e| {
        if e.to_string() == "EXPORT_CANCELLED" {
            return "EXPORT_CANCELLED".to_string();
        }
        format!("è§†é¢‘å¤„ç†å¤±è´¥: {}", e)
    })?;
    
    let processing_time = start_time.elapsed().as_secs_f64();
    
    Ok(VideoProcessResponse {
        success: true,
        message: "è§†é¢‘å¤„ç†å®Œæˆ".to_string(),
        original_duration: result.original_duration,
        processed_duration: result.processed_duration,
        silence_segments: result.silence_segments,
        total_silence_removed: result.total_silence_removed,
        compression_ratio: result.compression_ratio,
        output_path,
        processing_time,
    })
}

// æ‰¹é‡å¤„ç†
#[tauri::command]
pub async fn batch_process(
    input_paths: Vec<String>,
    output_dir: String,
    threshold_db: f64,
    min_silence_duration: f64,
) -> Result<Vec<video::ProcessResult>, String> {
    let result: Result<Vec<video::ProcessResult>, Box<dyn std::error::Error>> = video::batch_process_videos(
        &input_paths,
        &output_dir,
        threshold_db,
        min_silence_duration,
    ).await;
    result.map_err(|e| format!("æ‰¹é‡å¤„ç†å¤±è´¥: {}", e))
}

// ç”Ÿæˆè¾“å‡ºè·¯å¾„
fn generate_output_path(input_path: &str) -> String {
    let path = Path::new(input_path);
    let parent = path.parent().unwrap_or(Path::new("."));
    let stem = path.file_stem()
        .and_then(|s| s.to_str())
        .unwrap_or("output");
    let extension = path.extension()
        .and_then(|s| s.to_str())
        .unwrap_or("mp4");
    
    let timestamp = chrono::Local::now().format("%Y%m%d_%H%M%S");
    let filename = format!("{}_{}_cut.{}", stem, timestamp, extension);
    
    parent.join(filename).to_string_lossy().to_string()
}



